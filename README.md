# <span style="color:#9EB1FF; font-size:30.0pt">AUDIO GENERATION WITH DIFFUSION MODELS</span>


This repository is maintained by [**Carlos Hernández-Oliván**](https://carlosholivan.github.io/index.html)(carloshero@unizar.es) and it presents the State of the Art of Audio Generation with Diffusion models.

Make a pull request if you want to contribute to this references list.

All the images belong to their corresponding authors.

## Table of Contents

1. Papers
    - [2022](#2022)

2. Diffusion theory papers



## <span id="Papers" style="color:#9EB1FF; font-size:25.0pt">Papers</span>

### <span id="2022" style="color:#A8FF9E; font-size:20.0pt">2022</span>

#### <span id="bar-transformer" style="color:#FF9EC3; font-size:15.0pt">MM-Diffusion</span>

<img src="images/mm-diffusion.jpg" alt="isolated" width="400"/>

Ruan, Ludan and Ma, Yiyang and Yang, Huan and He, Huiguo and Liu, Bei and Fu, Jianlong and Yuan, Nicholas Jing and Jin, Qin and Guo, Baining. (2022). MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation.

[Paper](https://arxiv.org/pdf/2212.09478v1.pdf) [GitHub](https://github.com/researchmm/MM-Diffusion)

